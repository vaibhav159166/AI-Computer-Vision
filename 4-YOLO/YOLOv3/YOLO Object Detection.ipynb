{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time \n",
    "import cv2\n",
    "import numpy as np\n",
    "from model.yolo_model import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    '''\n",
    "    Resize, reduce and expand image.\n",
    "    \n",
    "    # Argument:\n",
    "        img: original image\n",
    "        \n",
    "    # Returns\n",
    "        image: ndarray(64,64,3), processed image\n",
    "        \n",
    "    '''\n",
    "    image=cv2.resize(img,(416,416),\n",
    "                    interpolation=cv2.INTER_CUBIC)\n",
    "    image=np.array(image,dtype='float32')\n",
    "    image/=255\n",
    "    image=np.expand_dims(image,axis=0)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>This function takes an original image img as input and performs several processing steps on it.</h4></b>\n",
    "\n",
    "Resize: The cv2.resize() function resizes the input image to a specified size (416, 416). It uses the cv2.INTER_CUBIC interpolation method, which is a higher quality interpolation method compared to others like cv2.INT ER_LINEAR. L\n",
    "\n",
    "Data type conversion: The resized image is then converted to a NumPy arr ay with dtype='float32'. This step ensures that the image data type is s uitable for further processing, typically in machine learning or compute r vision tasks.\n",
    "\n",
    "Normalization: The pixel values of the image are normalized by dividing each pixel value by 255. This step scales the pixel values to the range [0, 1], which is a common practice for neural network input data normali zation.\n",
    "\n",
    "Dimension expansion: Finally, np.expand_dims() is used to add an extra d imension to the processed image array. This is often necessary when deal ing with batch processing in deep learning frameworks, where the first d imension represents the batch size. In this case, axis e indicates that the new dimension is added as the first dimension.\n",
    "\n",
    "<b>The function returns the processed image with the specified shape (1.416, 416, 3), where 1 represents the batch size, 416 and 416 represent the image dimensions, and 3 represents the number of color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(file):\n",
    "    \"\"\"\n",
    "    Get classes name \n",
    "    \n",
    "    # Argument:\n",
    "        file: classes name for database\n",
    "        \n",
    "    # Returns:\n",
    "        class_names: List, classes name\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        class_names=f.readlines()\n",
    "    class_names=[c.strip() for c in class_names]\n",
    "    \n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The function is designed to read a file containing class names and return them as a list</b>\n",
    "Opening the file: The function takes a parameter file, which is the path to the file containing the class names. It then opens this file using a with statement, which ensures that file is properly closed after its suite finishes, even if an exception raised\n",
    "\n",
    "Reading Class Names: Inside the with block, f.readlines() reads all the lines from the file and returns them as a list of strings. Each string r epresents a class name.\n",
    "\n",
    "Stripping Newlines: Since readlines() includes the newline character \\n at the end of each line, the list of class names may contain trailing wh itespace. The list comprehension [c.strip() for c in class_names] is use d to remove leading and trailing whitespace (including newlines) from ea ch class name.\n",
    "\n",
    "Returning Class Names: The function then returns the list of class names\n",
    "\n",
    "<b>Overall, this function is a simple utility for exchanging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw(image, boxes, scores, classes, all_classes):\n",
    "    '''\n",
    "    Draw the boxes on the image\n",
    "    \n",
    "    # Arguments:\n",
    "        image: original image\n",
    "        boxes: ndarray, bounding boxes in (x, y, w, h) format\n",
    "        scores: ndarray, scores of objects\n",
    "        classes: ndarray, class indices of detected objects\n",
    "        all_classes: list of class names\n",
    "    '''\n",
    "    for box, score, c1 in zip(boxes, scores, classes):\n",
    "        x, y, w, h = box\n",
    "        \n",
    "        top = max(0, int(np.floor(x + 0.5)))\n",
    "        left = max(0, int(np.floor(y + 0.5)))\n",
    "        right = min(image.shape[1], int(np.floor(x + w + 0.5)))\n",
    "        bottom = min(image.shape[0], int(np.floor(y + h + 0.5)))\n",
    "        \n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(image, (top, left), (right, bottom), (255, 0, 0), 2)\n",
    "        \n",
    "        # Put the label with score\n",
    "        cv2.putText(image, '{0} {1:.2f}'.format(all_classes[c1], score),\n",
    "                    (top, left - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (0, 0, 255), 1,\n",
    "                    cv2.LINE_AA)\n",
    "        \n",
    "        print('Class: {0}, Score: {1:.2f}'.format(all_classes[c1], score))\n",
    "        print('Box coordinates (x, y, w, h): {0}'.format(box))\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is designed to draw bounding boxes around detected objects on an image, along with their class labels and confidence scores.\n",
    "\n",
    "Iterating Over Detected Objects:\n",
    "\n",
    "It iterates over each detected object using a for loop and zip(boxe s, scores, classes), where boxes, scores, and classes are arrays contain ing the bounding box coordinates, confidence scores, and class indices o f detected objects, respectively.\n",
    "\n",
    "Bounding Box Coordinates:\n",
    "\n",
    "For each detected object, it unpacks the bounding box coordinates (x, y, w, h) from box.\n",
    "\n",
    "It calculates the top-left (top, left) and bottom-right (right, bott om) coordinates of the bounding box. These coordinates are used to draw\n",
    "\n",
    "Annotating with Class Label and Score:\n",
    "\n",
    "It annotates the bounding box with the class label and confidence sc ore using cv2.putText(). The label and score are formatted with the clas s name obtained from all_classes[cl] (where cl is the class index) and t he confidence score. This annotation is placed slightly above the top-le ft corner of the bounding box with a red color (0, 0, 255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(image,yolo,all_classes):\n",
    "    \"\"\"Use yolo v3 to detect images.\n",
    "\n",
    "    # Argument:\n",
    "        image: original image.\n",
    "        yolo: VOLO, yolo model.\n",
    "        all_classes: all classes name.\n",
    "\n",
    "    # Returns:\n",
    "        image: processed image.\n",
    "    \"\"\"\n",
    "\n",
    "    pimage=process_image(image)\n",
    "    #The image is first processed into a format that the YOLO model \n",
    "    #expects, typically involving resizing, normalizing, and possibly \n",
    "    #transforming the image to fit the input shape for the YOLO model.\n",
    "    \n",
    "    start = time.time()\n",
    "    boxes, classes, scores =yolo.predict(pimage, image.shape) \n",
    "    end = time.time()\n",
    "    \n",
    "    print('time: {0:.2f}s'.format(end - start))\n",
    "    \n",
    "# Here, the function calls YOLO's predict method on the processed image\n",
    "# (pimage). This method returns three things:\n",
    "\n",
    "# boxes: coordinates of bounding boxes for detected objects.\n",
    "\n",
    "# classes: the class indices (e.g., '0' for 'person', '1' for 'car', etc\n",
    "\n",
    "    if boxes is not None:\n",
    "        draw(image,boxes,scores,classes,all_classes)\n",
    "        \n",
    "#IF YOLO detects any objects (i.e., boxes is not None), \n",
    "#the draw function is called. This function will typically:\n",
    "#Draw bounding boxes on the original image.\n",
    "#Label each box with the class name (using all_classes).\n",
    "#Optionally include the confidence score\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def detect_video(video, yolo, all_classes):\n",
    "    video_path = os.path.join(\"C:/AI_New/4-YOLO/YOLOv3/videos\",\"C:\\AI_New\\4-YOLO\\YOLOv3\\videos\\test\")\n",
    "    camera = cv2.VideoCapture(video_path)\n",
    "    cv2.namedWindow(\"detection\", cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    # Prepare for saving the detected video\n",
    "    frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    sz = (frame_width, frame_height)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    output_dir = os.path.join(\"C:/AI_New/4-YOLO/YOLOv3/videos\", \"res\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    vout = cv2.VideoWriter(os.path.join(output_dir, video), fourcc, 30.0, sz)  # Assuming 30 FPS for output video\n",
    "\n",
    "    while True:\n",
    "        res, frame = camera.read()\n",
    "        \n",
    "        if not res:\n",
    "            break\n",
    "        \n",
    "        image = detect_image(frame, yolo, all_classes)\n",
    "        cv2.imshow('detection', image)\n",
    "        \n",
    "        vout.write(image)\n",
    "        \n",
    "        # Exit on 'Esc' key\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    vout.release()\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo=YOLO(0.6,0.5)\n",
    "file=\"C:/AI_New/4-YOLO/YOLOv3/data/coco_classes.txt\"\n",
    "all_classes=get_classes(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.00s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=\"C:/AI_New/4-YOLO/YOLOv3/images/test/person.jpg\"\n",
    "image=cv2.imread(\"C:/AI_New/4-YOLO/YOLOv3/images/test/person.jpg\")\n",
    "image=detect_image(image,yolo,all_classes)\n",
    "cv2.imwrite(\"C:/AI_New/4-YOLO/YOLOv3/images/res/\"+f,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
